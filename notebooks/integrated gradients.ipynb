{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os.path\n",
    "sys.path.append('/scratch/pramodkm/vqa/vqa_kazemi2017show/')\n",
    "import math\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import config\n",
    "import data\n",
    "import model_IG\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "log = torch.load('/scratch/pramodkm/vqa/vqa_kazemi2017show/logs/2017-08-04_00.55.19.pth')\n",
    "tokens = len(log['vocab']['question']) + 1\n",
    "\n",
    "net = torch.nn.DataParallel(model_IG.Net(tokens))\n",
    "net.load_state_dict(log['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabulary\n",
    "with open(config.vocabulary_path, 'r') as fd:\n",
    "    vocab_json = json.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding matrix\n",
    "question_emb_lookup = log['weights']['module.text.embedding.weight']\n",
    "embedding = nn.Embedding(question_emb_lookup.shape[0], question_emb_lookup.shape[1], padding_idx=0)\n",
    "embedding.weight.data = question_emb_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "val_loader = data.get_loader(val=True)\n",
    "LOADER=val_loader\n",
    "PREFIX=\"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "val E000:   0% 0/950 [00:00<?, ?it/s]\u001b[A\n",
      "/scratch/pramodkm/vqa/vqa_kazemi2017show/model_IG.py:135: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attention = F.softmax(attention)\n",
      "val E000:   0% 1/950 [00:01<27:06,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6289062523283064\n",
      "0.6773437517695129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val E000:   1% 5/950 [00:02<06:36,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6242187512107193\n",
      "0.6109375031664968\n",
      "0.571093752514571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "val E000:   1% 7/950 [00:02<05:05,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5929687530733645\n",
      "0.6015625027939677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "val E000:   1% 8/950 [00:02<04:42,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5867187534458935\n",
      "0.6757812523283064\n",
      "0.6140625020489097\n"
     ]
    }
   ],
   "source": [
    "tq = tqdm(LOADER, desc='{} E{:03d}'.format(PREFIX, 0), ncols=0)\n",
    "net.eval()\n",
    "answ = []\n",
    "idxs = []\n",
    "accs = []\n",
    "num_batches = 0\n",
    "for v, q, a, idx, q_len in tq:\n",
    "        var_params = {\n",
    "            'volatile': True,\n",
    "            'requires_grad': False,\n",
    "        }\n",
    "        v = Variable(v.cuda(async=True), **var_params)\n",
    "        q = Variable(q.cuda(async=True), **var_params)\n",
    "        a = Variable(a.cuda(async=True), **var_params)\n",
    "        q_len = Variable(q_len.cuda(async=True), **var_params)\n",
    "        \n",
    "        q = embedding(q)\n",
    "        \n",
    "        out = net(v, q, q_len)\n",
    "        acc = utils.batch_accuracy(out.data, a.data).cpu()\n",
    "        \n",
    "        _, answer = out.data.cpu().max(dim=1)\n",
    "        answ.append(answer.view(-1))\n",
    "        accs.append(acc.view(-1))\n",
    "        idxs.append(idx.view(-1).clone())\n",
    "        print(acc.mean())\n",
    "        num_batches += 1\n",
    "        if num_batches == 10:\n",
    "            break\n",
    "\n",
    "answ = list(torch.cat(answ, dim=0))\n",
    "accs = list(torch.cat(accs, dim=0))\n",
    "idxs = list(torch.cat(idxs, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(question_emb_lookup.shape[0], question_emb_lookup.shape[1], padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.weight.data = question_emb_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 ,.,.) = \n",
       " -3.2798e-02  5.1392e-02  1.6251e-02  ...  -1.2319e-02 -8.2559e-02  3.3580e-02\n",
       "  1.6407e-03  2.5175e-03 -1.6903e-02  ...   1.5478e-02  9.4804e-03  1.0341e-02\n",
       " -1.1436e-01 -7.8576e-02  1.3111e-01  ...   6.0400e-03 -3.7864e-02 -5.7790e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       "\n",
       "( 1 ,.,.) = \n",
       " -3.7956e-02 -2.9700e-02 -1.1624e-02  ...   1.5651e-02  4.8440e-03  5.7062e-02\n",
       "  1.6407e-03  2.5175e-03 -1.6903e-02  ...   1.5478e-02  9.4804e-03  1.0341e-02\n",
       "  5.8533e-02 -5.8102e-02 -2.0755e-01  ...  -2.7952e-02  9.1103e-02  1.8481e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       "\n",
       "( 2 ,.,.) = \n",
       "  5.1743e-03 -3.1932e-02  3.5067e-03  ...   2.1017e-02  5.8285e-02 -2.8138e-02\n",
       " -3.7956e-02 -2.9700e-02 -1.1624e-02  ...   1.5651e-02  4.8440e-03  5.7062e-02\n",
       "  1.6407e-03  2.5175e-03 -1.6903e-02  ...   1.5478e-02  9.4804e-03  1.0341e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       "... \n",
       "\n",
       "(125,.,.) = \n",
       " -3.7956e-02 -2.9700e-02 -1.1624e-02  ...   1.5651e-02  4.8440e-03  5.7062e-02\n",
       "  1.6407e-03  2.5175e-03 -1.6903e-02  ...   1.5478e-02  9.4804e-03  1.0341e-02\n",
       "  1.5534e-01  8.4293e-02 -4.4729e-02  ...  -8.4443e-02 -1.0622e-01 -4.7494e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       "\n",
       "(126,.,.) = \n",
       " -3.7956e-02 -2.9700e-02 -1.1624e-02  ...   1.5651e-02  4.8440e-03  5.7062e-02\n",
       " -9.1111e-03  8.4114e-02 -9.0162e-02  ...   7.2284e-03 -2.1582e-02  8.1988e-03\n",
       "  2.0059e-02 -8.9497e-04  8.0875e-02  ...  -9.7440e-02  1.7583e-02 -1.0336e-01\n",
       "                 ...                   ⋱                   ...                \n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       "\n",
       "(127,.,.) = \n",
       " -3.7956e-02 -2.9700e-02 -1.1624e-02  ...   1.5651e-02  4.8440e-03  5.7062e-02\n",
       " -9.1111e-03  8.4114e-02 -9.0162e-02  ...   7.2284e-03 -2.1582e-02  8.1988e-03\n",
       "  5.4601e-02  1.1067e-01 -1.2210e-01  ...   5.1904e-02 -7.6969e-03  5.4914e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       " -7.6968e-03 -2.3634e-03 -5.5749e-03  ...   7.1667e-04  4.6250e-03 -3.2087e-03\n",
       "[torch.cuda.FloatTensor of size 128x23x300 (GPU 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
