{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-1fa471ddbed7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import os.path\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython.display import HTML, Image, clear_output, display\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import data\n",
    "import model_IG\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths, parameters, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which GPU device to use?\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "# path to pretrained model\n",
    "MODEL_FILE = '../logs/2017-08-04_00.55.19.pth'\n",
    "\n",
    "# TSV file to write attributions \n",
    "ATTRS_TSV = '/scratch/pramodkm/acl18/vqa/tsv/attrs.tsv'\n",
    "\n",
    "# HTML file to pretty display attributions\n",
    "# The folder containing the images is assumed to be named \"val\" \n",
    "# and be in the same directory as this HTML\n",
    "ATTRS_HTML = '/scratch/pramodkm/acl18/vqa/attrs.html'\n",
    "\n",
    "# Number of steps in Riemann integral computation for Integrated Gradients\n",
    "NUM_STEPS = 2000\n",
    "\n",
    "# Sample size of dataset to use in all computations of this notebooks\n",
    "MAX_NUM_BATCHES = 50 # corresponds to 6400 inputs\n",
    "\n",
    "# File (EPS format) for writing the overstability curve\n",
    "OVERSTABILITY_CURVE_FILE = '/scratch/pramodkm/acl18/vqa/overstability.eps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../model_IG.py:95: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(w)\n",
      "../model_IG.py:91: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(self.embedding.weight)\n",
      "../model_IG.py:44: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "log = torch.load(MODEL_FILE)\n",
    "tokens = len(log['vocab']['question']) + 1\n",
    "\n",
    "net = torch.nn.DataParallel(model_IG.Net(tokens))\n",
    "net.load_state_dict(log['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabulary\n",
    "with open(config.vocabulary_path, 'r') as fd:\n",
    "    vocab_json = json.load(fd)\n",
    "reverse_vocab_question = dict(\n",
    "    [(v, k) for k, v in vocab_json['question'].items()])\n",
    "reverse_vocab_answer = dict([(v, k) for k, v in vocab_json['answer'].items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embedding matrix for question words\n",
    "question_emb_lookup = log['weights']['module.text.embedding.weight']\n",
    "embedding = nn.Embedding(\n",
    "    question_emb_lookup.shape[0], question_emb_lookup.shape[1], padding_idx=0)\n",
    "embedding.weight.data = question_emb_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "val_loader = data.get_loader(val=True)\n",
    "LOADER = val_loader\n",
    "PREFIX = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image index dict\n",
    "reverse_coco_idxs = dict(\n",
    "    [(v, k) for k, v in val_loader.dataset.coco_id_to_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(a):\n",
    "    \"\"\" Get the answer that at least 3 turkers have agreed on \"\"\"\n",
    "    indices = torch.nonzero(a >= 3)\n",
    "    if len(indices) == 0:\n",
    "        return ''\n",
    "    return '|'.join([reverse_vocab_answer[int(index)] for index in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a few items\n",
    "if not os.path.isdir(os.path.dirname(ATTRS_TSV)):\n",
    "    os.makedirs(os.path.dirname(ATTRS_TSV))\n",
    "\n",
    "var_params = {\n",
    "    'volatile': True,\n",
    "    'requires_grad': False,\n",
    "}\n",
    "\n",
    "# number of batches for the integral summation for computing attributions\n",
    "num_batches_ig = int(np.ceil(NUM_STEPS/val_loader.batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_embedding = embedding.weight.data[0, :]\n",
    "\n",
    "\n",
    "def scale_input(q_emb, num_batches=1):\n",
    "    \"\"\" Create scaled versions of input and stack along batch dimension\n",
    "    q_emb shape = (q_length, emb_dim)\n",
    "    \"\"\"\n",
    "    num_points = config.batch_size*num_batches\n",
    "    scale = 1.0/num_points\n",
    "    step = (q_emb.unsqueeze(0) -\n",
    "            padding_embedding.unsqueeze(0).unsqueeze(0)) * scale\n",
    "    ans = torch.cat([torch.add(padding_embedding, step*i)\n",
    "                     for i in range(num_points)], dim=0)\n",
    "    return ans, step.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attributions(q_emb, q_len, v, idx, num_batches=5, answer=None):\n",
    "    \"\"\" compute attributions for all examples in a given batch \"\"\"\n",
    "    ans = ''\n",
    "    for batch_i in range(config.batch_size):\n",
    "        scaled_q_emb, step = scale_input(\n",
    "            q_emb[batch_i, :, :], num_batches=num_batches)\n",
    "        diff = 0\n",
    "        total_grads = 0\n",
    "        for j in range(num_batches):\n",
    "            repeated_q_len = (torch.torch.ones_like(q_len)*q_len[batch_i])\n",
    "            repeated_v = (torch.ones_like(v)*v[batch_i])\n",
    "            batch_scaled_q_emb = scaled_q_emb[j*config.batch_size:(\n",
    "                j+1)*config.batch_size]\n",
    "            with torch.autograd.set_grad_enabled(True):\n",
    "                scaled_answer, gradients = net(\n",
    "                    repeated_v, batch_scaled_q_emb, repeated_q_len, compute_gradient=True, ans_index=int(answer[batch_i]))\n",
    "            # at this point, shape(gradients) = 128 x 23 x 300\n",
    "            total_grads += torch.sum(gradients, dim=0)\n",
    "            if j == 0:\n",
    "                diff -= scaled_answer[0, answer[batch_i]]\n",
    "                baseline_softmax = scaled_answer[0, :]\n",
    "            if j == num_batches - 1:\n",
    "                diff += scaled_answer[-1, answer[batch_i]]\n",
    "        del scaled_q_emb, repeated_q_len, repeated_v, batch_scaled_q_emb, gradients\n",
    "        attributions = torch.sum(total_grads * step, dim=1)\n",
    "        area = torch.sum(attributions, dim=0)\n",
    "        print('--------------------------')\n",
    "        print(('diff: ', float(diff)))\n",
    "        print(('area: ', float(area)))\n",
    "        if abs(float(diff) - float(area)) > 0.1:\n",
    "            print(('WARNING: attribution sanity check not matching up!! Diff = ', abs(\n",
    "                float(diff) - float(area))))\n",
    "\n",
    "        predicted_answer = reverse_vocab_answer[int(answer[batch_i])]\n",
    "        correct_answer = get_answer(a[batch_i, :])\n",
    "        _, baseline_topk_answers = baseline_softmax.topk(1)\n",
    "        baseline_topk_answers = ', '.join(\n",
    "            [reverse_vocab_answer[int(i)] for i in baseline_topk_answers])\n",
    "\n",
    "        if baseline_topk_answers[0] == predicted_answer:\n",
    "            attributions = attributions*0\n",
    "\n",
    "        #print('Predicted answer: ', predicted_answer)\n",
    "        #print('Baseline top k answers : ', ' | '.join(baseline_topk_answers))\n",
    "        #print('Prediction is correct?: ', int(acc[batch_i]))\n",
    "        #print('Image ID: ', val_loader.dataset.coco_ids[int(idx[batch_i])])\n",
    "        question_attrs = []\n",
    "        for j, w in enumerate(q[batch_i, :]):\n",
    "            if int(w) != 0:\n",
    "                #print(reverse_vocab_question[int(w)], ': ', float(attributions[j]))\n",
    "                question_attrs.append(\n",
    "                    '|'.join([str(reverse_vocab_question[int(w)]), str(float(attributions[j]))]))\n",
    "        tsv_string = ['||'.join(question_attrs), baseline_topk_answers, predicted_answer, correct_answer, str(\n",
    "            int(acc[batch_i])), str(val_loader.dataset.coco_ids[int(idx[batch_i])])]\n",
    "        ans += '\\t'.join(tsv_string) + '\\n'\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "val E000:   0% 0/950 [00:00<?, ?it/s]\u001b[A\u001b[A../model_IG.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attention = F.softmax(attention)\n",
      "../model_IG.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  softmax = torch.nn.functional.softmax(answer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "('diff: ', 0.18070226907730103)\n",
      "('area: ', 0.18094158172607422)\n",
      "--------------------------\n",
      "('diff: ', 0.5486360788345337)\n",
      "('area: ', 0.5488159656524658)\n",
      "--------------------------\n",
      "('diff: ', 0.12886281311511993)\n",
      "('area: ', 0.12885290384292603)\n",
      "--------------------------\n",
      "('diff: ', 0.19869333505630493)\n",
      "('area: ', 0.1986498236656189)\n",
      "--------------------------\n",
      "('diff: ', 0.6828103065490723)\n",
      "('area: ', 0.6830248236656189)\n",
      "--------------------------\n",
      "('diff: ', 0.15882307291030884)\n",
      "('area: ', 0.15880736708641052)\n",
      "--------------------------\n",
      "('diff: ', 0.4037765860557556)\n",
      "('area: ', 0.4037899971008301)\n",
      "--------------------------\n",
      "('diff: ', 0.3646804094314575)\n",
      "('area: ', 0.36466723680496216)\n",
      "--------------------------\n",
      "('diff: ', 0.04525918513536453)\n",
      "('area: ', 0.045273564755916595)\n",
      "--------------------------\n",
      "('diff: ', 0.9091885089874268)\n",
      "('area: ', 0.9095503091812134)\n",
      "--------------------------\n",
      "('diff: ', 0.9797325134277344)\n",
      "('area: ', 0.9795140027999878)\n",
      "--------------------------\n",
      "('diff: ', -0.3730389177799225)\n",
      "('area: ', -0.3731270134449005)\n",
      "--------------------------\n",
      "('diff: ', 0.6551578640937805)\n",
      "('area: ', 0.6552033424377441)\n",
      "--------------------------\n",
      "('diff: ', -0.024724304676055908)\n",
      "('area: ', -0.02458108961582184)\n",
      "--------------------------\n",
      "('diff: ', 0.49271973967552185)\n",
      "('area: ', 0.49277251958847046)\n",
      "--------------------------\n",
      "('diff: ', 0.3632427453994751)\n",
      "('area: ', 0.3632621765136719)\n",
      "--------------------------\n",
      "('diff: ', 0.3324166536331177)\n",
      "('area: ', 0.33203011751174927)\n",
      "--------------------------\n",
      "('diff: ', 0.33699339628219604)\n",
      "('area: ', 0.33665552735328674)\n",
      "--------------------------\n",
      "('diff: ', 0.08730153739452362)\n",
      "('area: ', 0.08725099265575409)\n",
      "--------------------------\n",
      "('diff: ', 0.17270439863204956)\n",
      "('area: ', 0.17273524403572083)\n",
      "--------------------------\n",
      "('diff: ', 0.7497044205665588)\n",
      "('area: ', 0.7499589323997498)\n",
      "--------------------------\n",
      "('diff: ', 0.8374118804931641)\n",
      "('area: ', 0.837577223777771)\n",
      "--------------------------\n",
      "('diff: ', 0.059255897998809814)\n",
      "('area: ', 0.05951535701751709)\n",
      "--------------------------\n",
      "('diff: ', 0.4975071847438812)\n",
      "('area: ', 0.4976278841495514)\n",
      "--------------------------\n",
      "('diff: ', 0.14916959404945374)\n",
      "('area: ', 0.14916397631168365)\n",
      "--------------------------\n",
      "('diff: ', 0.36660337448120117)\n",
      "('area: ', 0.36675846576690674)\n",
      "--------------------------\n",
      "('diff: ', 0.1370883584022522)\n",
      "('area: ', 0.1371975541114807)\n",
      "--------------------------\n",
      "('diff: ', 0.04751158878207207)\n",
      "('area: ', 0.04757603630423546)\n",
      "--------------------------\n",
      "('diff: ', 0.06618093699216843)\n",
      "('area: ', 0.06616377830505371)\n",
      "--------------------------\n",
      "('diff: ', 0.24752745032310486)\n",
      "('area: ', 0.2474880814552307)\n",
      "--------------------------\n",
      "('diff: ', 0.3419104218482971)\n",
      "('area: ', 0.3421226143836975)\n",
      "--------------------------\n",
      "('diff: ', 0.4829501509666443)\n",
      "('area: ', 0.4829994738101959)\n",
      "--------------------------\n",
      "('diff: ', 0.5104840993881226)\n",
      "('area: ', 0.5106810927391052)\n",
      "--------------------------\n",
      "('diff: ', 0.530864953994751)\n",
      "('area: ', 0.5301728248596191)\n",
      "--------------------------\n",
      "('diff: ', 0.06120795011520386)\n",
      "('area: ', 0.06112562492489815)\n",
      "--------------------------\n",
      "('diff: ', 0.7562689781188965)\n",
      "('area: ', 0.7562851905822754)\n",
      "--------------------------\n",
      "('diff: ', 0.4406600296497345)\n",
      "('area: ', 0.44076797366142273)\n",
      "--------------------------\n",
      "('diff: ', 0.40072599053382874)\n",
      "('area: ', 0.40073126554489136)\n",
      "--------------------------\n",
      "('diff: ', 0.5393410325050354)\n",
      "('area: ', 0.5393061637878418)\n",
      "--------------------------\n",
      "('diff: ', 0.5582804083824158)\n",
      "('area: ', 0.5580828189849854)\n",
      "--------------------------\n",
      "('diff: ', 0.1714416891336441)\n",
      "('area: ', 0.1714327335357666)\n",
      "--------------------------\n",
      "('diff: ', 0.4004651606082916)\n",
      "('area: ', 0.40051597356796265)\n",
      "--------------------------\n",
      "('diff: ', 0.12153661251068115)\n",
      "('area: ', 0.12170722335577011)\n",
      "--------------------------\n",
      "('diff: ', 0.9193777441978455)\n",
      "('area: ', 0.9196048378944397)\n",
      "--------------------------\n",
      "('diff: ', 0.18005496263504028)\n",
      "('area: ', 0.1804010570049286)\n",
      "--------------------------\n",
      "('diff: ', 0.8632738590240479)\n",
      "('area: ', 0.8634884357452393)\n",
      "--------------------------\n",
      "('diff: ', 0.46423089504241943)\n",
      "('area: ', 0.4643036127090454)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method tqdm.__del__ of val E000:  11% 101/950 [44:39<6:15:25, 26.53s/it]>\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 878, in __del__\n",
      "    self.close()\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 1097, in close\n",
      "    self._decr_instances(self)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 438, in _decr_instances\n",
      "    cls._instances.remove(instance)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: <weakref at 0x7fc69c186db8; to 'tqdm' at 0x7fc69cc61630>\n",
      "Exception ignored in: <bound method tqdm.__del__ of val E000:   4% 42/950 [15:30<5:35:17, 22.16s/it]>\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 878, in __del__\n",
      "    self.close()\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 1097, in close\n",
      "    self._decr_instances(self)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 438, in _decr_instances\n",
      "    cls._instances.remove(instance)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: <weakref at 0x7fc69ccd6138; to 'tqdm' at 0x7fc681f4ed30>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "('diff: ', 0.5412090420722961)\n",
      "('area: ', 0.541146993637085)\n",
      "--------------------------\n",
      "('diff: ', 0.22412948310375214)\n",
      "('area: ', 0.22388367354869843)\n",
      "--------------------------\n",
      "('diff: ', 0.10552164912223816)\n",
      "('area: ', 0.10540381819009781)\n",
      "--------------------------\n",
      "('diff: ', -0.005904674530029297)\n",
      "('area: ', -0.005699649453163147)\n",
      "--------------------------\n",
      "('diff: ', 0.528976559638977)\n",
      "('area: ', 0.529047429561615)\n",
      "--------------------------\n",
      "('diff: ', 0.16673916578292847)\n",
      "('area: ', 0.16669538617134094)\n",
      "--------------------------\n",
      "('diff: ', 0.6459755301475525)\n",
      "('area: ', 0.6455185413360596)\n",
      "--------------------------\n",
      "('diff: ', 0.9850893020629883)\n",
      "('area: ', 0.9849807620048523)\n",
      "--------------------------\n",
      "('diff: ', 0.04381340742111206)\n",
      "('area: ', 0.04382854327559471)\n",
      "--------------------------\n",
      "('diff: ', 0.09538118541240692)\n",
      "('area: ', 0.09531401097774506)\n",
      "--------------------------\n",
      "('diff: ', 0.49279454350471497)\n",
      "('area: ', 0.49296143651008606)\n",
      "--------------------------\n",
      "('diff: ', 0.21360766887664795)\n",
      "('area: ', 0.2136857807636261)\n",
      "--------------------------\n",
      "('diff: ', 0.449633926153183)\n",
      "('area: ', 0.4497279226779938)\n",
      "--------------------------\n",
      "('diff: ', 0.2318451702594757)\n",
      "('area: ', 0.23183439671993256)\n",
      "--------------------------\n",
      "('diff: ', 0.8532041907310486)\n",
      "('area: ', 0.8530160188674927)\n",
      "--------------------------\n",
      "('diff: ', 0.23429039120674133)\n",
      "('area: ', 0.23445290327072144)\n",
      "--------------------------\n",
      "('diff: ', 0.2566225528717041)\n",
      "('area: ', 0.25651639699935913)\n",
      "--------------------------\n",
      "('diff: ', 0.5332698822021484)\n",
      "('area: ', 0.5332444310188293)\n",
      "--------------------------\n",
      "('diff: ', 0.933236300945282)\n",
      "('area: ', 0.9328877925872803)\n",
      "--------------------------\n",
      "('diff: ', 0.3600520193576813)\n",
      "('area: ', 0.3600940704345703)\n",
      "--------------------------\n",
      "('diff: ', 0.5568603873252869)\n",
      "('area: ', 0.5569396018981934)\n",
      "--------------------------\n",
      "('diff: ', 0.16619741916656494)\n",
      "('area: ', 0.16628876328468323)\n",
      "--------------------------\n",
      "('diff: ', 0.16404473781585693)\n",
      "('area: ', 0.16407543420791626)\n",
      "--------------------------\n",
      "('diff: ', 0.1574409306049347)\n",
      "('area: ', 0.15746083855628967)\n",
      "--------------------------\n",
      "('diff: ', 0.1197403073310852)\n",
      "('area: ', 0.11978576332330704)\n",
      "--------------------------\n",
      "('diff: ', 0.9914279580116272)\n",
      "('area: ', 0.9911109209060669)\n",
      "--------------------------\n",
      "('diff: ', 0.5435428619384766)\n",
      "('area: ', 0.5435875654220581)\n",
      "--------------------------\n",
      "('diff: ', 0.43479371070861816)\n",
      "('area: ', 0.4350461959838867)\n",
      "--------------------------\n",
      "('diff: ', 0.20540973544120789)\n",
      "('area: ', 0.20532295107841492)\n",
      "--------------------------\n",
      "('diff: ', 0.24464371800422668)\n",
      "('area: ', 0.244563490152359)\n",
      "--------------------------\n",
      "('diff: ', 0.37758520245552063)\n",
      "('area: ', 0.3776353895664215)\n",
      "--------------------------\n",
      "('diff: ', 0.37611883878707886)\n",
      "('area: ', 0.3762091398239136)\n",
      "--------------------------\n",
      "('diff: ', 0.42462825775146484)\n",
      "('area: ', 0.424826979637146)\n",
      "--------------------------\n",
      "('diff: ', 0.5037328600883484)\n",
      "('area: ', 0.5037833452224731)\n",
      "--------------------------\n",
      "('diff: ', 0.6296666264533997)\n",
      "('area: ', 0.6295503973960876)\n",
      "--------------------------\n",
      "('diff: ', 0.050095122307538986)\n",
      "('area: ', 0.050058651715517044)\n",
      "--------------------------\n",
      "('diff: ', -0.10267525911331177)\n",
      "('area: ', -0.10278395563364029)\n",
      "--------------------------\n",
      "('diff: ', 0.45444822311401367)\n",
      "('area: ', 0.45449578762054443)\n",
      "--------------------------\n",
      "('diff: ', 0.2798156142234802)\n",
      "('area: ', 0.28001031279563904)\n",
      "--------------------------\n",
      "('diff: ', 0.22211052477359772)\n",
      "('area: ', 0.22214275598526)\n",
      "--------------------------\n",
      "('diff: ', 0.8739168643951416)\n",
      "('area: ', 0.873927652835846)\n",
      "--------------------------\n",
      "('diff: ', 0.1166938990354538)\n",
      "('area: ', 0.11673276126384735)\n",
      "--------------------------\n",
      "('diff: ', 0.5344427824020386)\n",
      "('area: ', 0.5345797538757324)\n",
      "--------------------------\n",
      "('diff: ', 0.9925519824028015)\n",
      "('area: ', 0.9922866821289062)\n",
      "--------------------------\n",
      "('diff: ', 0.41301974654197693)\n",
      "('area: ', 0.4129030406475067)\n",
      "--------------------------\n",
      "('diff: ', 0.3664463758468628)\n",
      "('area: ', 0.36630505323410034)\n",
      "--------------------------\n",
      "('diff: ', 0.733168363571167)\n",
      "('area: ', 0.7331974506378174)\n",
      "--------------------------\n",
      "('diff: ', 0.2612450122833252)\n",
      "('area: ', 0.2611497640609741)\n",
      "--------------------------\n",
      "('diff: ', 0.9949337244033813)\n",
      "('area: ', 0.9951587915420532)\n",
      "--------------------------\n",
      "('diff: ', 0.17827200889587402)\n",
      "('area: ', 0.1783890426158905)\n",
      "--------------------------\n",
      "('diff: ', 0.31768983602523804)\n",
      "('area: ', 0.3177033066749573)\n",
      "--------------------------\n",
      "('diff: ', 0.039592523127794266)\n",
      "('area: ', 0.03961721062660217)\n",
      "--------------------------\n",
      "('diff: ', 0.43158769607543945)\n",
      "('area: ', 0.4319143295288086)\n",
      "--------------------------\n",
      "('diff: ', 0.3640058636665344)\n",
      "('area: ', 0.36410820484161377)\n",
      "--------------------------\n",
      "('diff: ', 0.5086936950683594)\n",
      "('area: ', 0.5088564157485962)\n",
      "--------------------------\n",
      "('diff: ', 0.24353021383285522)\n",
      "('area: ', 0.2435821294784546)\n",
      "--------------------------\n",
      "('diff: ', 0.034954916685819626)\n",
      "('area: ', 0.034955691546201706)\n",
      "--------------------------\n",
      "('diff: ', 0.9738415479660034)\n",
      "('area: ', 0.9738515615463257)\n",
      "--------------------------\n",
      "('diff: ', 0.7225078344345093)\n",
      "('area: ', 0.7224671244621277)\n",
      "--------------------------\n",
      "('diff: ', 0.298221230506897)\n",
      "('area: ', 0.2983623147010803)\n",
      "--------------------------\n",
      "('diff: ', 0.3763852119445801)\n",
      "('area: ', 0.37651631236076355)\n",
      "--------------------------\n",
      "('diff: ', 0.6801214218139648)\n",
      "('area: ', 0.6806025505065918)\n",
      "--------------------------\n",
      "('diff: ', 0.5386508703231812)\n",
      "('area: ', 0.5388725399971008)\n",
      "--------------------------\n",
      "('diff: ', 0.37675991654396057)\n",
      "('area: ', 0.37689632177352905)\n",
      "--------------------------\n",
      "('diff: ', 0.053598761558532715)\n",
      "('area: ', 0.05362321436405182)\n",
      "--------------------------\n",
      "('diff: ', 0.23333081603050232)\n",
      "('area: ', 0.23348170518875122)\n",
      "--------------------------\n",
      "('diff: ', 0.5183695554733276)\n",
      "('area: ', 0.5183529853820801)\n",
      "--------------------------\n",
      "('diff: ', 0.05088686943054199)\n",
      "('area: ', 0.05084998905658722)\n",
      "--------------------------\n",
      "('diff: ', 0.19426512718200684)\n",
      "('area: ', 0.19452141225337982)\n",
      "--------------------------\n",
      "('diff: ', 0.40749984979629517)\n",
      "('area: ', 0.4076399803161621)\n",
      "--------------------------\n",
      "('diff: ', 0.023279786109924316)\n",
      "('area: ', 0.023458436131477356)\n",
      "--------------------------\n",
      "('diff: ', 0.34180718660354614)\n",
      "('area: ', 0.341769814491272)\n",
      "--------------------------\n",
      "('diff: ', 0.6459733843803406)\n",
      "('area: ', 0.6460888385772705)\n",
      "--------------------------\n",
      "('diff: ', 0.2905694246292114)\n",
      "('area: ', 0.29076647758483887)\n",
      "--------------------------\n",
      "('diff: ', 0.18356329202651978)\n",
      "('area: ', 0.18361836671829224)\n",
      "--------------------------\n",
      "('diff: ', 0.37268340587615967)\n",
      "('area: ', 0.37279874086380005)\n",
      "--------------------------\n",
      "('diff: ', 0.4358175992965698)\n",
      "('area: ', 0.4360660910606384)\n",
      "--------------------------\n",
      "('diff: ', 0.17426399886608124)\n",
      "('area: ', 0.1742866337299347)\n",
      "--------------------------\n",
      "('diff: ', 0.09446316957473755)\n",
      "('area: ', 0.09448307752609253)\n",
      "--------------------------\n",
      "('diff: ', 0.34816718101501465)\n",
      "('area: ', 0.3482508957386017)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "val E000:   0% 1/950 [01:25<22:24:51, 85.03s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "('diff: ', 0.528058648109436)\n",
      "('area: ', 0.5281053185462952)\n",
      "--------------------------\n",
      "('diff: ', 0.2930716872215271)\n",
      "('area: ', 0.2931501865386963)\n",
      "--------------------------\n",
      "('diff: ', 0.17275816202163696)\n",
      "('area: ', 0.1728382706642151)\n",
      "--------------------------\n",
      "('diff: ', 0.8862912654876709)\n",
      "('area: ', 0.8863835334777832)\n",
      "--------------------------\n",
      "('diff: ', 0.6431472897529602)\n",
      "('area: ', 0.6432040333747864)\n",
      "--------------------------\n",
      "('diff: ', 0.2616961598396301)\n",
      "('area: ', 0.26170265674591064)\n",
      "--------------------------\n",
      "('diff: ', 0.7612995505332947)\n",
      "('area: ', 0.7611421942710876)\n",
      "--------------------------\n",
      "('diff: ', 0.046140819787979126)\n",
      "('area: ', 0.04612869769334793)\n",
      "--------------------------\n",
      "('diff: ', 0.5459368824958801)\n",
      "('area: ', 0.5461190938949585)\n",
      "--------------------------\n",
      "('diff: ', 0.6874357461929321)\n",
      "('area: ', 0.6871944069862366)\n",
      "--------------------------\n",
      "('diff: ', 0.19469763338565826)\n",
      "('area: ', 0.1948392391204834)\n",
      "--------------------------\n",
      "('diff: ', -0.47125178575515747)\n",
      "('area: ', -0.4709709882736206)\n",
      "--------------------------\n",
      "('diff: ', 0.6386087536811829)\n",
      "('area: ', 0.6389662623405457)\n",
      "--------------------------\n",
      "('diff: ', 0.34671878814697266)\n",
      "('area: ', 0.34678390622138977)\n",
      "--------------------------\n",
      "('diff: ', 0.030126512050628662)\n",
      "('area: ', 0.030172312632203102)\n",
      "--------------------------\n",
      "('diff: ', 0.12878674268722534)\n",
      "('area: ', 0.12866440415382385)\n",
      "--------------------------\n",
      "('diff: ', 0.7246536612510681)\n",
      "('area: ', 0.7245665788650513)\n",
      "--------------------------\n",
      "('diff: ', 0.09414241462945938)\n",
      "('area: ', 0.0935206338763237)\n",
      "--------------------------\n",
      "('diff: ', 0.4568353295326233)\n",
      "('area: ', 0.4569098949432373)\n",
      "--------------------------\n",
      "('diff: ', 0.9316512942314148)\n",
      "('area: ', 0.9318073987960815)\n",
      "--------------------------\n",
      "('diff: ', 0.7443481087684631)\n",
      "('area: ', 0.7442998886108398)\n",
      "--------------------------\n",
      "('diff: ', 0.28635090589523315)\n",
      "('area: ', 0.2863727807998657)\n",
      "--------------------------\n",
      "('diff: ', 0.515296220779419)\n",
      "('area: ', 0.515499472618103)\n",
      "--------------------------\n",
      "('diff: ', 0.9844061732292175)\n",
      "('area: ', 0.9843036532402039)\n",
      "--------------------------\n",
      "('diff: ', 0.23760254681110382)\n",
      "('area: ', 0.23755934834480286)\n",
      "--------------------------\n",
      "('diff: ', 0.20834483206272125)\n",
      "('area: ', 0.20841354131698608)\n",
      "--------------------------\n",
      "('diff: ', 0.3196513056755066)\n",
      "('area: ', 0.31978991627693176)\n",
      "--------------------------\n",
      "('diff: ', 0.06572797894477844)\n",
      "('area: ', 0.06576341390609741)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-414:\n",
      "Process Process-411:\n",
      "Process Process-415:\n",
      "Process Process-412:\n",
      "Process Process-409:\n",
      "Process Process-416:\n",
      "Process Process-410:\n",
      "Process Process-413:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-688cefe1cd60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         attrs_tsv_string = compute_attributions(\n\u001b[0;32m---> 24\u001b[0;31m             q_emb, q_len, v, idx, num_batches=num_batches_ig, answer=answer)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moutf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs_tsv_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-136-32f053b80060>\u001b[0m in \u001b[0;36mcompute_attributions\u001b[0;34m(q_emb, q_len, v, idx, num_batches, answer)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 scaled_answer, gradients = net(\n\u001b[0;32m---> 16\u001b[0;31m                     repeated_v, batch_scaled_q_emb, repeated_q_len, compute_gradient=True, ans_index=int(answer[batch_i]))\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;31m# at this point, shape(gradients) = 128 x 23 x 300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtotal_grads\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/pramodkm/vqa/vqa_kazemi2017show/model_IG.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, v, q_emb, q_len, compute_gradient, ans_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/pramodkm/vqa/vqa_kazemi2017show/model_IG.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embedded, q_len)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m#embedded = self.embedding(q)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mtanhed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtanhed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# fast pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmight_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_tensors_permissive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \"\"\"\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackPadded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Script to compute attributions for a fixed number of batches\n",
    "net.train()\n",
    "accs = []\n",
    "num_batches = 0\n",
    "with open(ATTRS_TSV, 'w') as outf:\n",
    "    # iterator over the validation dataset\n",
    "    tq = tqdm(LOADER, desc='{} E{:03d}'.format(PREFIX, 0), ncols=0)\n",
    "    for v, q, a, idx, q_len in tq:\n",
    "\n",
    "        v = Variable(v.cuda(async=True), **var_params)\n",
    "        q = Variable(q.cuda(async=True), **var_params)\n",
    "        a = Variable(a.cuda(async=True), **var_params)\n",
    "        q_len = Variable(q_len.cuda(async=True), **var_params)\n",
    "\n",
    "        q_emb = embedding(q)\n",
    "\n",
    "        out = net(v, q_emb, q_len)\n",
    "\n",
    "        acc = utils.batch_accuracy(out.data, a.data).cpu()\n",
    "\n",
    "        _, answer = out.data.cpu().max(dim=1)\n",
    "\n",
    "        attrs_tsv_string = compute_attributions(\n",
    "            q_emb, q_len, v, idx, num_batches=num_batches_ig, answer=answer)\n",
    "\n",
    "        outf.write(attrs_tsv_string)\n",
    "        outf.flush()\n",
    "\n",
    "        accs.append(np.array(acc.view(-1)))\n",
    "\n",
    "        if num_batches >= MAX_NUM_BATCHES:\n",
    "            break\n",
    "        num_batches += 1\n",
    "\n",
    "accs = list(np.concatenate(accs, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over 6 inputs: 0.6783854166666666\n"
     ]
    }
   ],
   "source": [
    "# Accuracy \n",
    "print('Accuracy over',len(accs),'inputs:',np.mean(np.array(accs) >= 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attrs(tokens, attrs):\n",
    "    html_text = \"\"\n",
    "    for i, tok in enumerate(tokens):\n",
    "        r, g, b = get_color(attrs[i])\n",
    "        html_text += \" <strong><span style='size:16;color:rgb(%d,%d,%d)'>%s</span></strong>\" % (\n",
    "            r, g, b, tok)\n",
    "    return html_text\n",
    "\n",
    "\n",
    "def get_latex(tokens, attrs):\n",
    "    ans = \"\"\n",
    "    for i, tok in enumerate(tokens):\n",
    "        [r, g, b] = [w/256.0 for w in get_color(attrs[i])]\n",
    "        ans += \" {\\color[rgb]{%f,%f,%f}%s}\" % (r, g, b, tok)\n",
    "    return ans\n",
    "\n",
    "\n",
    "def normalize_attrs(attrs):\n",
    "    \"\"\" normalize attributions to between -1 and 1 \"\"\"\n",
    "    bound = max(abs(attrs.max()), abs(attrs.min()))\n",
    "    return attrs/bound\n",
    "\n",
    "\n",
    "def get_color(attr):\n",
    "    \"\"\" attr is assumed to be between -1 and 1 \"\"\"\n",
    "    if attr > 0:\n",
    "        return int(128*attr) + 127, 128 - int(64*attr), 128 - int(64*attr)\n",
    "    return 128 + int(64*attr), 128 + int(64*attr), int(-128*attr) + 127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_visualization_html(tsv_filename, html_filename):\n",
    "    html_str = '<head><link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css\" integrity=\"sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm\" crossorigin=\"anonymous\"></head>'\n",
    "    html_str += '<body> <div class=\"container\"> <h3> Visualizations of the attributions for the Visual QA network <br> <small> Red indicates high values, blue and gray indicates low values <br> A green (or red) block before the question indicates whether the network got the answer right (or wrong)</small></h3></div><br>'\n",
    "    with open(tsv_filename) as f, open(html_filename, 'w') as outf:\n",
    "        html_str += '<div class=\"container\">'\n",
    "        html_str += '-'*40 + '<br>'\n",
    "        outf.write(html_str)\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            question_attrs, baseline_topk_answers, predicted_answer, correct_answer, is_correct, image_id = line.split(\n",
    "                '\\t')\n",
    "            question_tokens = []\n",
    "            attrs = []\n",
    "            for word_attr in question_attrs.split(','):\n",
    "                word, attr = word_attr.split('|')\n",
    "                question_tokens.append(word)\n",
    "                attrs.append(float(attr))\n",
    "            html_str = visualize_attrs(\n",
    "                question_tokens, normalize_attrs(np.array(attrs)))\n",
    "\n",
    "            if is_correct == '1':\n",
    "                html_str = '<span style=\"background-color:green\">&nbsp&nbsp</span> ' + html_str\n",
    "            else:\n",
    "                html_str = '<span style=\"background-color:red\">&nbsp&nbsp</span> ' + html_str\n",
    "            html_str += '<br>(prediction, ground truth) = (' + predicted_answer + ', ' + correct_answer + ')'\n",
    "            html_str += '<br>prediction :' + predicted_answer\n",
    "            html_str += '<br>baseline topk answers: ' + baseline_topk_answers\n",
    "            html_str += '<br>image ID: ' + str(image_id)\n",
    "            html_str += '<br><img src=\"val2014/COCO_val2014_' + '0' * \\\n",
    "                (12 - len(str(image_id))) + str(image_id) + \\\n",
    "                '.jpg\" width=\"256\" height=\"256\"></img><br><br>'\n",
    "            #display(Image('/scratch/pramodkm/vqa/data_vqa1.0/val2014/COCO_val2014_' + '0'*(12 - len(str(image_id))) + str(image_id) + '.jpg', width=256, height=256))\n",
    "            outf.write(html_str + '\\n')\n",
    "        outf.write('</div></body>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-ee2191b00e58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m make_visualization_html(tsv_filename = ATTRS_TSV, \n\u001b[0;32m----> 2\u001b[0;31m                        html_filename = ATTRS_HTML)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-3d92a4f90ca5>\u001b[0m in \u001b[0;36mmake_visualization_html\u001b[0;34m(tsv_filename, html_filename)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mword_attr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestion_attrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mquestion_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "make_visualization_html(tsv_filename = ATTRS_TSV, \n",
    "                       html_filename = ATTRS_HTML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack by prefixing sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def question_concatenation_accuracy(net, phrase, suffix=False):\n",
    "    \"\"\" compute accuracy when phrases are prefixed/suffixed \"\"\"\n",
    "    net.eval()\n",
    "    \n",
    "    prefix = []\n",
    "    for word in phrase.split():\n",
    "        prefix.append(vocab_json['question'][word])\n",
    "    prefix = torch.LongTensor(prefix) \n",
    "    prefix = prefix.unsqueeze(0).repeat(config.batch_size,1)\n",
    "    accs = []\n",
    "    num_batches = 0\n",
    "    # iterator over the validation dataset\n",
    "    tq = tqdm(LOADER, desc='{} E{:03d}'.format(PREFIX, 0), ncols=0)\n",
    "    for v, q, a, idx, q_len in tq:\n",
    "\n",
    "        if not suffix:\n",
    "            q = torch.cat([prefix, q], dim=1)[:,:23] ## 23 because question_length is configured to cap at 23\n",
    "        else:\n",
    "            for i in range(config.batch_size):\n",
    "                nnz_ix = int((torch.nonzero(q[i,:].cpu())).squeeze().max()) + 1\n",
    "                if nnz_ix >= q.shape[1]:\n",
    "                    continue\n",
    "                q[i, nnz_ix:] = prefix[0, :23-nnz_ix]\n",
    "        q = q.contiguous()\n",
    "        \n",
    "        q_len = q_len + prefix.shape[1]\n",
    "        q_len = torch.min(q_len, torch.LongTensor([23]).expand_as(q_len))\n",
    "\n",
    "\n",
    "        v = Variable(v.cuda(async=True), **var_params)\n",
    "        q = Variable(q.cuda(async=True), **var_params)\n",
    "        a = Variable(a.cuda(async=True), **var_params)\n",
    "        q_len = Variable(q_len.cuda(async=True), **var_params)\n",
    "\n",
    "        q_emb = embedding(q)\n",
    "\n",
    "        out = net(v, q_emb, q_len)\n",
    "\n",
    "        acc = utils.batch_accuracy(out.data, a.data).cpu()\n",
    "\n",
    "        accs.append(np.array(acc.view(-1)))\n",
    "\n",
    "        if num_batches >= MAX_NUM_BATCHES:\n",
    "            break\n",
    "        num_batches += 1\n",
    "\n",
    "    accs = list(np.concatenate(accs))\n",
    "    return np.mean(np.array(accs) >= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "val E000:   0% 0/950 [00:00<?, ?it/s]\u001b[A\u001b[A../model_IG.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attention = F.softmax(attention)\n",
      "\n",
      "\n",
      "val E000:   0% 1/950 [00:01<28:09,  1.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   0% 3/950 [00:02<11:29,  1.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   1% 5/950 [00:02<07:14,  2.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   1% 7/950 [00:02<05:27,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   1% 9/950 [00:02<04:45,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   1% 11/950 [00:02<04:13,  3.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   1% 13/950 [00:03<03:41,  4.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   2% 15/950 [00:03<03:19,  4.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   2% 17/950 [00:03<03:02,  5.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   2% 19/950 [00:03<02:48,  5.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   2% 21/950 [00:03<02:56,  5.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   2% 23/950 [00:04<02:45,  5.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 25/950 [00:04<02:38,  5.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 27/950 [00:04<02:38,  5.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 29/950 [00:04<02:36,  5.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 30/950 [00:05<02:34,  5.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 31/950 [00:05<02:33,  5.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 32/950 [00:05<02:32,  6.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 33/950 [00:05<02:36,  5.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   4% 35/950 [00:05<02:30,  6.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   4% 37/950 [00:05<02:24,  6.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   4% 39/950 [00:06<02:22,  6.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   4% 41/950 [00:06<02:19,  6.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 43/950 [00:06<02:19,  6.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 44/950 [00:06<02:19,  6.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 45/950 [00:06<02:18,  6.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 46/950 [00:07<02:17,  6.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 47/950 [00:07<02:17,  6.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 48/950 [00:07<02:17,  6.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 49/950 [00:07<02:17,  6.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 50/950 [00:07<02:17,  6.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   0% 0/950 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   0% 1/950 [00:01<25:30,  1.61s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   0% 2/950 [00:02<20:08,  1.27s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   0% 4/950 [00:02<10:28,  1.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   1% 6/950 [00:02<07:15,  2.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   1% 8/950 [00:02<05:41,  2.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   1% 10/950 [00:03<05:14,  2.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   1% 13/950 [00:03<04:13,  3.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   2% 15/950 [00:03<03:47,  4.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   2% 18/950 [00:03<03:19,  4.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   2% 20/950 [00:04<03:11,  4.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   2% 22/950 [00:04<03:08,  4.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   2% 23/950 [00:04<03:05,  5.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   3% 24/950 [00:04<03:03,  5.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   3% 25/950 [00:04<03:01,  5.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   3% 26/950 [00:05<03:03,  5.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   3% 29/950 [00:05<02:49,  5.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   3% 31/950 [00:05<02:44,  5.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   3% 32/950 [00:05<02:43,  5.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   3% 33/950 [00:05<02:43,  5.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   4% 34/950 [00:06<02:46,  5.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   4% 36/950 [00:06<02:39,  5.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   4% 38/950 [00:06<02:37,  5.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   4% 40/950 [00:06<02:32,  5.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   4% 42/950 [00:06<02:29,  6.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   5% 43/950 [00:07<02:32,  5.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 45/950 [00:07<02:28,  6.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 46/950 [00:07<02:30,  6.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 48/950 [00:07<02:26,  6.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 50/950 [00:08<02:24,  6.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   0% 0/950 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   0% 1/950 [00:01<27:11,  1.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   0% 3/950 [00:02<12:04,  1.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   1% 5/950 [00:02<07:34,  2.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   1% 7/950 [00:02<05:39,  2.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   1% 9/950 [00:02<05:08,  3.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   1% 11/950 [00:03<04:47,  3.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   1% 13/950 [00:03<04:12,  3.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   2% 16/950 [00:03<03:33,  4.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   2% 18/950 [00:03<03:16,  4.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   2% 20/950 [00:04<03:12,  4.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   2% 22/950 [00:04<03:01,  5.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   3% 24/950 [00:04<02:55,  5.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   3% 26/950 [00:04<02:49,  5.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   3% 27/950 [00:04<02:48,  5.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   3% 28/950 [00:05<02:49,  5.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   3% 30/950 [00:05<02:50,  5.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   3% 32/950 [00:05<02:42,  5.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   4% 34/950 [00:05<02:35,  5.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   4% 36/950 [00:06<02:33,  5.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   4% 38/950 [00:06<02:31,  6.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   4% 39/950 [00:06<02:30,  6.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   4% 40/950 [00:06<02:29,  6.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   4% 41/950 [00:06<02:28,  6.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   4% 42/950 [00:06<02:28,  6.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   5% 43/950 [00:07<02:27,  6.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   5% 44/950 [00:07<02:27,  6.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   5% 45/950 [00:07<02:26,  6.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   5% 46/950 [00:07<02:27,  6.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   5% 48/950 [00:07<02:23,  6.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   5% 49/950 [00:07<02:22,  6.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   5% 50/950 [00:07<02:22,  6.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   0% 0/950 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "val E000:   0% 1/950 [00:02<40:37,  2.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   0% 3/950 [00:02<14:07,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   1% 6/950 [00:02<07:26,  2.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   1% 8/950 [00:02<05:49,  2.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   1% 10/950 [00:03<05:19,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   1% 12/950 [00:03<04:37,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   1% 14/950 [00:03<04:06,  3.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   2% 16/950 [00:03<03:42,  4.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   2% 18/950 [00:04<03:28,  4.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   2% 20/950 [00:04<03:26,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   2% 22/950 [00:04<03:13,  4.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 24/950 [00:04<03:01,  5.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 26/950 [00:05<02:58,  5.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 28/950 [00:05<02:49,  5.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 30/950 [00:05<02:46,  5.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 32/950 [00:05<02:46,  5.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   4% 34/950 [00:06<02:42,  5.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   4% 36/950 [00:06<02:36,  5.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   4% 38/950 [00:06<02:32,  5.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   4% 40/950 [00:06<02:29,  6.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   4% 42/950 [00:06<02:30,  6.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 44/950 [00:07<02:25,  6.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 46/950 [00:07<02:21,  6.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 48/950 [00:07<02:20,  6.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 50/950 [00:07<02:19,  6.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   0% 0/950 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   0% 1/950 [00:01<25:42,  1.63s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   0% 2/950 [00:01<14:06,  1.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   0% 3/950 [00:02<11:35,  1.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   0% 4/950 [00:02<10:00,  1.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   1% 6/950 [00:02<06:56,  2.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "val E000:   1% 8/950 [00:02<05:25,  2.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "val E000:   1% 10/950 [00:02<04:36,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   1% 12/950 [00:03<04:42,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   2% 15/950 [00:03<03:54,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   2% 17/950 [00:04<03:43,  4.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   2% 20/950 [00:04<03:17,  4.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   2% 22/950 [00:04<03:07,  4.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 24/950 [00:04<03:04,  5.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 25/950 [00:05<03:06,  4.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 27/950 [00:05<02:56,  5.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 29/950 [00:05<02:59,  5.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 31/950 [00:05<02:51,  5.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   3% 33/950 [00:06<02:53,  5.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   4% 35/950 [00:06<02:46,  5.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   4% 37/950 [00:06<02:41,  5.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   4% 39/950 [00:06<02:39,  5.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   4% 41/950 [00:07<02:35,  5.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 43/950 [00:07<02:33,  5.90it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val E000:   5% 45/950 [00:07<02:30,  6.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 46/950 [00:07<02:29,  6.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 47/950 [00:07<02:32,  5.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 49/950 [00:08<02:28,  6.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "val E000:   5% 50/950 [00:08<02:27,  6.11it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix attacks:\n",
      "<zip object at 0x7fc69ccc4548>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "PHRASES = [\n",
    "    'in not a lot of words',\n",
    "    'in not many words',\n",
    "    'what is the answer to',\n",
    "    'tell me',\n",
    "    'answer this'\n",
    "]\n",
    "\n",
    "prefix_attack_accs = []\n",
    "for phrase in PHRASES:\n",
    "    prefix_attack_accs.append(question_concatenation_accuracy(net, phrase))\n",
    "print(\"Prefix attacks:\")\n",
    "print([w for w in zip(PHRASES, prefix_attack_accs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overstability analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_list = []\n",
    "top_k = 1\n",
    "with open(ATTRS_TSV) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        question_attrs = line.split('\\t')[0]\n",
    "        question_tokens = []\n",
    "        attrs = []\n",
    "        for word_attr in question_attrs.split('||'): \n",
    "            word, attr = word_attr.split('|')\n",
    "            question_tokens.append(word)\n",
    "            attrs.append(float(attr))\n",
    "        k = min(top_k, len(question_tokens))\n",
    "        # get top k words by attribution \n",
    "        counts_list.extend([question_tokens[i].strip() for i in np.argpartition(attrs, -k)[-k:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_whitelist = [vocab_json['question'][w] for w in 'the, is, what, are, this, in, on, a, of, how, many, color, there, people, where'.split(', ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 22]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_whitelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "val E000:   0% 0/950 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['many']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../model_IG.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attention = F.softmax(attention)\n",
      "\n",
      "val E000:   0% 1/950 [00:02<35:47,  2.26s/it]\u001b[A\n",
      "val E000:   0% 2/950 [00:02<19:16,  1.22s/it]\u001b[A\n",
      "val E000:   0% 3/950 [00:02<14:00,  1.13it/s]\u001b[A\n",
      "val E000:   0% 4/950 [00:02<11:17,  1.40it/s]\u001b[A\n",
      "val E000:   1% 5/950 [00:03<09:37,  1.64it/s]\u001b[A\n",
      "val E000:   1% 6/950 [00:03<08:33,  1.84it/s]\u001b[A\n",
      "val E000:   1% 7/950 [00:03<07:44,  2.03it/s]\u001b[A\n",
      "val E000:   1% 8/950 [00:03<07:03,  2.22it/s]\u001b[A\n",
      "val E000:   1% 9/950 [00:03<06:38,  2.36it/s]\u001b[A\n",
      "val E000:   1% 10/950 [00:03<06:12,  2.53it/s]\u001b[A\n",
      "val E000:   5% 50/950 [00:10<03:16,  4.58it/s]Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fc681a6bf98>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 344, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 493, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 737, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "val E000:   0% 0/950 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg question length orig:  6.197763480392157\n",
      "avg question length new:  1.0042892156862746\n",
      "accuracy for  1.0  is 0.2938419\n",
      "['many', 'color']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "val E000:   0% 1/950 [00:02<36:12,  2.29s/it]\u001b[A\n",
      "val E000:   0% 2/950 [00:02<19:39,  1.24s/it]\u001b[A\n",
      "val E000:   0% 3/950 [00:02<13:57,  1.13it/s]\u001b[A\n",
      "val E000:   5% 50/950 [00:11<03:18,  4.53it/s]\n",
      "val E000:   0% 0/950 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg question length orig:  6.197763480392157\n",
      "avg question length new:  1.0052083333333333\n",
      "accuracy for  2.0  is 0.32919732\n",
      "['what', 'many', 'color']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "val E000:   0% 1/950 [00:01<29:55,  1.89s/it]Process Process-441:\n",
      "Process Process-447:\n",
      "Traceback (most recent call last):\n",
      "Process Process-442:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"../data.py\", line 150, in __getitem__\n",
      "    v = self._load_image(image_id)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"../data.py\", line 139, in _load_image\n",
      "    img = dataset[index].astype('float32')\n",
      "KeyboardInterrupt\n",
      "  File \"../data.py\", line 150, in __getitem__\n",
      "    v = self._load_image(image_id)\n",
      "Process Process-445:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../data.py\", line 139, in _load_image\n",
      "    img = dataset[index].astype('float32')\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"../data.py\", line 39, in collate_fn\n",
      "    return data.dataloader.default_collate(batch)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in default_collate\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "KeyboardInterrupt\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 115, in default_collate\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "KeyboardInterrupt\n",
      "Process Process-446:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "Process Process-444:\n",
      "Process Process-448:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../data.py\", line 39, in collate_fn\n",
      "    return data.dataloader.default_collate(batch)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in default_collate\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"../data.py\", line 39, in collate_fn\n",
      "    return data.dataloader.default_collate(batch)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in default_collate\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 115, in default_collate\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 115, in default_collate\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-443:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"../data.py\", line 39, in collate_fn\n",
      "    return data.dataloader.default_collate(batch)\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in default_collate\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/scratch/pramodkm/tensorflow_gpu_python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 115, in default_collate\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-32fe1287dbfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvar_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvar_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvar_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "curve_data = []\n",
    "all_accs = []\n",
    "for K in np.unique(np.floor(np.geomspace(1, len(Counter(counts_list)), 25))):\n",
    "    # take K most top attributed words\n",
    "    whitelist = set([vocab_json['question'][w] for w, c in Counter(counts_list).most_common(int(K))])\n",
    "    print([reverse_vocab_question[w] for w in whitelist])\n",
    "    \n",
    "    accs = []\n",
    "    num_batches = 0\n",
    "    avg_question_length_orig = 0\n",
    "    avg_question_length_new = 0\n",
    "    num_questions = 0\n",
    "    # iterator over the validation dataset\n",
    "    tq = tqdm(LOADER, desc='{} E{:03d}'.format(PREFIX, 0), ncols=0)\n",
    "    for v, q, a, idx, q_len in tq:\n",
    "\n",
    "        old_q = np.asarray(q).copy()\n",
    "        old_q_len = np.asarray(q_len).copy()\n",
    "\n",
    "        new_q = np.zeros([config.batch_size, 23])\n",
    "        for batch_i in range(config.batch_size):\n",
    "            len_counter = 0\n",
    "            avg_question_length_orig += int(q_len[batch_i])\n",
    "            for word_i, w in enumerate(q[batch_i,:int(q_len[batch_i])]):\n",
    "                if int(w) == 0 or int(w) in whitelist:\n",
    "                    new_q[batch_i, len_counter] = int(w)\n",
    "                    #new_q[batch_i, word_i] = int(w)\n",
    "                    len_counter += 1\n",
    "            if len_counter == 0:\n",
    "                len_counter = 1\n",
    "            avg_question_length_new += int(len_counter)\n",
    "            num_questions += 1\n",
    "            q_len[batch_i] = len_counter\n",
    "        q_len, sorted_idxs = torch.sort(q_len, descending=True)\n",
    "        new_q = new_q[sorted_idxs, :]\n",
    "        idx = idx[sorted_idxs]\n",
    "        v = v[sorted_idxs,:,:,:]\n",
    "        a = a[sorted_idxs, :]\n",
    "        old_q = old_q[sorted_idxs, :]\n",
    "        old_q_len = old_q_len[sorted_idxs]\n",
    "        q = torch.LongTensor(new_q)\n",
    "\n",
    "        v = Variable(v.cuda(async=True), **var_params)\n",
    "        q = Variable(q.cuda(async=True), **var_params)\n",
    "        a = Variable(a.cuda(async=True), **var_params)\n",
    "        q_len = Variable(q_len.cuda(async=True), **var_params)\n",
    "\n",
    "        q_emb = embedding(q)\n",
    "\n",
    "        out = net(v, q_emb, q_len)\n",
    "\n",
    "        acc = utils.batch_accuracy(out.data, a.data).cpu()\n",
    "\n",
    "        accs.append(np.array(acc.view(-1)))\n",
    "\n",
    "        if num_batches >= MAX_NUM_BATCHES:\n",
    "            break\n",
    "        num_batches += 1\n",
    "\n",
    "    accs = list(np.concatenate(accs))\n",
    "    print(\"avg question length orig: \", float(avg_question_length_orig)/num_questions)\n",
    "    print(\"avg question length new: \", float(avg_question_length_new)/num_questions)\n",
    "    print(\"accuracy for \", K, \" is\", np.mean(accs))\n",
    "    curve_data.append((K, np.mean(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies by size of vocab\n",
      "[(1.0, 0.2938419), (2.0, 0.32919732)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracies by size of vocab\")\n",
    "print(curve_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OVERSTABILITY_CURVE_FILE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-e6e746f19a28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num. words in vocab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOVERSTABILITY_CURVE_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OVERSTABILITY_CURVE_FILE' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([w[0] for w in curve_data], [w[1] for w in curve_data])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('num. words in vocab')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig(OVERSTABILITY_CURVE_FILE, format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject ablation attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_list = []\n",
    "top_k = 5\n",
    "with open(ATTRS_TSV) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        question_attrs, predicted_answer, correct_answer, is_correct, image_id = line.split('\\t')\n",
    "        question_tokens = []\n",
    "        attrs = []\n",
    "        for word_attr in question_attrs.split(','):\n",
    "            if len(word_attr.split('|')) < 2:\n",
    "                print('skipped')\n",
    "                continue\n",
    "            word, attr = word_attr.split('|')\n",
    "            question_tokens.append(word)\n",
    "            attrs.append(float(attr))\n",
    "        k = min(top_k, len(question_tokens))\n",
    "        counts_list.extend([question_tokens[i].strip() for i in np.argpartition(attrs, -k)[-k:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unattributed_words = set(vocab_json['question'].keys()) - set(counts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unattributed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(unattributed_words)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "sent = \"how symmetrical are the white bricks on either side of the building\"\n",
    "doc=nlp(sent)\n",
    "\n",
    "sub_toks = [tok for tok in doc if (tok.dep_ == \"nobj\") ]\n",
    "\n",
    "print(sub_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[d.dep_ for d in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tq = tqdm(LOADER, desc='{} E{:03d}'.format(PREFIX, 0), ncols=0)\n",
    "net.eval()\n",
    "answ = []\n",
    "idxs = []\n",
    "accs = []\n",
    "num_iters = 0\n",
    "batch_id = 0\n",
    "attrs_tsv_string = ''\n",
    "for v, q, a, idx, q_len in tq:\n",
    "        \n",
    "        var_params = {\n",
    "            'volatile': False,\n",
    "            'requires_grad': False,        \n",
    "        }\n",
    "        out_string = ''\n",
    "        for i in range(config.batch_size):\n",
    "            if len(np.nonzero(a[i, :] >= 3))==0:\n",
    "                continue\n",
    "            answers = [reverse_vocab_answer[int(w)] for w in np.nonzero(a[i, :] >= 3)]\n",
    "            if 'yes' in answers or 'no' in answers:\n",
    "                continue\n",
    "            string_question = [reverse_vocab_question[int(w)] if int(w) != 0 else '' for w in q[i, :]]\n",
    "            out_string += '-'*50 + '\\n'\n",
    "            out_string += 'orig: ' + ' '.join(string_question) + '\\n'\n",
    "            out_string += 'answers: ' + ' '.join(answers) + '\\n'\n",
    "            doc = nlp(' '.join(string_question))\n",
    "            pos_tags = [d.dep_ for d in doc]\n",
    "            #print(pos_tags)\n",
    "            subject_index = [i for i, t in enumerate(pos_tags) if 'nsubj' in t]\n",
    "            if len(subject_index) == 0:\n",
    "                continue\n",
    "            q[i, subject_index[0]] = vocab_json['question']['civilian']\n",
    "            string_question = [reverse_vocab_question[int(w)] if int(w) != 0 else '' for w in q[i, :]]\n",
    "            out_string += 'ablated: ' + ' '.join(string_question) + '\\n'\n",
    "\n",
    "            \n",
    "        v = Variable(v.cuda(async=True), **var_params)\n",
    "        q = Variable(q.cuda(async=True), **var_params)\n",
    "        a = Variable(a.cuda(async=True), **var_params)\n",
    "        q_len = Variable(q_len.cuda(async=True), **var_params)\n",
    "        \n",
    "        q_emb = embedding(q)\n",
    "        \n",
    "        out = net(v, q_emb, q_len)            \n",
    "        \n",
    "        acc = utils.batch_accuracy(out.data, a.data).cpu()\n",
    "        \n",
    "        _, answer = out.data.cpu().max(dim=1)\n",
    "        \n",
    "#        attrs_tsv_string = compute_attributions(q_emb, q_len, v, idx, num_batches=5)\n",
    "        \n",
    "#        outf.write(attrs_tsv_string)\n",
    "        #for i in range(config.batch_size):\n",
    "            #if int(acc[i]) >= 1.0:\n",
    "                #print(out_string)\n",
    "        \n",
    "        answ.append(answer.view(-1))\n",
    "        accs.append(acc.view(-1))\n",
    "        idxs.append(idx.view(-1).clone())\n",
    "        print(acc.mean())\n",
    "        num_iters += 1\n",
    "        batch_id += 1\n",
    "        #print(' '.join([reverse_vocab_question[int(w)] for w in q[3,:] if int(w)!=0]))\n",
    "        #print(acc[3])\n",
    "        if num_iters == 5:\n",
    "            break\n",
    "            \n",
    "#outf.close()\n",
    "\n",
    "answ = list(torch.cat(answ, dim=0))\n",
    "accs = list(torch.cat(accs, dim=0))\n",
    "idxs = list(torch.cat(idxs, dim=0))\n",
    "\n",
    "print('final: ' + str(np.mean(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_vocab_answer[int(np.nonzero(a[0, :] > 3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(a[i, :] >= 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image specific bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import scipy.stats as stats\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data=open('/scratch/pramodkm/vqa/data_vqa1.0/OpenEnded_mscoco_val2014_questions.json').read()\n",
    "data = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data=open('/scratch/pramodkm/vqa/data_vqa1.0/mscoco_val2014_annotations.json').read()\n",
    "annot_data = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_data['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ans = dict()\n",
    "for ans_annot in annot_data['annotations']:\n",
    "    turk_answers = [ans['answer'] for ans in ans_annot['answers']]\n",
    "    if ans_annot['image_id'] not in image_ans:\n",
    "        image_ans[ans_annot['image_id']] = [turk_answers]\n",
    "    else:\n",
    "        image_ans[ans_annot['image_id']].append(turk_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_baseline_answers(tokens, attrs, image_ans):\n",
    "    html_text = \"\"\n",
    "    count = 0\n",
    "    for i, tok in enumerate(tokens):\n",
    "        r,g,b = get_color(attrs[i])\n",
    "        val = []\n",
    "        for ans in image_ans:\n",
    "            val += [sum(tok == np.array(ans))]\n",
    "        if sum(np.array(val)>=3)>0:\n",
    "            tok = '<u>' + tok + '</u>'\n",
    "            count += 1\n",
    "        html_text += \"<span style='size:16;color:rgb(%d,%d,%d)'>%s</span>, \" % (r, g, b, tok)\n",
    "    return html_text, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tq = tqdm(LOADER, desc='{} E{:03d}'.format(PREFIX, 0), ncols=0)\n",
    "net.eval()\n",
    "answ = []\n",
    "idxs = []\n",
    "accs = []\n",
    "num_iters = 0\n",
    "batch_id = 0\n",
    "outf = open('/scratch/pramodkm/vqa/tsv/baseline_answers.html','w')\n",
    "html_str = '<html><head><link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css\" integrity=\"sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm\" crossorigin=\"anonymous\"></head>'\n",
    "html_str += '<body><div class=\"container\"> <h3> Top 15 answer classes for each image </h3><br>Generated by passing an empty question to the network. Underlined classes appear as answers to questions on the image. <br>'\n",
    "html_str += '<table class=\"table\">'\n",
    "outf.write(html_str)\n",
    "\n",
    "question = 'what color besides blue is there'\n",
    "question_tokens = torch.LongTensor([vocab_json['question'][w] for w in question.strip().split()] + [0]*(23-len(question.strip().split())))\n",
    "question_tokens = question_tokens.unsqueeze(0).repeat(config.batch_size,1)\n",
    "new_q_len = torch.LongTensor([len(question.strip().split())])\n",
    "new_q_len = new_q_len.repeat(config.batch_size)\n",
    "\n",
    "covered_image_ids = set()\n",
    "\n",
    "avg_count = []\n",
    "for v, q, a, idx, q_len in tq:\n",
    "        \n",
    "        var_params = {\n",
    "            'volatile': False,\n",
    "            'requires_grad': False,        \n",
    "        }\n",
    "        \n",
    "        q = question_tokens\n",
    "            \n",
    "        q_len = new_q_len\n",
    "        \n",
    "        v = Variable(v.cuda(async=True), **var_params)\n",
    "        q = Variable(q.cuda(async=True), **var_params)\n",
    "        a = Variable(a.cuda(async=True), **var_params)\n",
    "        q_len = Variable(q_len.cuda(async=True), **var_params)\n",
    "        \n",
    "        q_emb = embedding(q)\n",
    "                \n",
    "        out = net(v, q_emb, q_len)    \n",
    "        \n",
    "        softmax = torch.nn.functional.softmax(out)\n",
    "        \n",
    "        acc = utils.batch_accuracy(out.data, a.data).cpu()\n",
    "        \n",
    "        _, answer = out.data.cpu().max(dim=1)\n",
    "\n",
    "        # for baseline answers\n",
    "        baseline_q = q * 0   \n",
    "            \n",
    "        baseline_q_len = q_len/q_len\n",
    "        \n",
    "        baseline_q_emb = embedding(baseline_q)\n",
    "                \n",
    "        baseline_out = net(v, baseline_q_emb, baseline_q_len)    \n",
    "        \n",
    "        baseline_softmax = torch.nn.functional.softmax(baseline_out)\n",
    "\n",
    "\n",
    "        for batch_i in range(config.batch_size):\n",
    "            baseline_probs, baseline_idxs = baseline_softmax[batch_i, :].sort(descending=True)\n",
    "            baseline_answers = [reverse_vocab_answer[int(ix)] for ix in baseline_idxs]\n",
    "            \n",
    "            baseline_probs = [float(prob) for prob in baseline_probs]\n",
    "            print_k = 15\n",
    "            #outf.write('... ' + visualize_baseline_answers(baseline_answers[-10:], baseline_probs[-10:]))\n",
    "            image_id = str(val_loader.dataset.coco_ids[int(idx[batch_i])])\n",
    "            if image_id in covered_image_ids:\n",
    "                continue\n",
    "            covered_image_ids.add(image_id)\n",
    "            #outf.write('<br>Question: ' + ' '.join([reverse_vocab_question[int(w)] for w in q[batch_i, :] if int(w)!=0]))\n",
    "            #outf.write('<br>Pred. ans.: ' + reverse_vocab_answer[answer[batch_i]])\n",
    "            outf.write('<br><tr><td><img src=\"val2014/COCO_val2014_' + '0'*(12 - len(str(image_id))) + str(image_id) + '.jpg\" width=\"256\" height=\"256\"></img></td>')\n",
    "            vis_string, count = visualize_baseline_answers(baseline_answers[:print_k], baseline_probs[:print_k], image_ans[int(image_id)])\n",
    "            avg_count.append(count)\n",
    "            outf.write('<td>' + vis_string + '<br> #classes appearing as answers: ' + str(count) + '</td></tr>')\n",
    "            \n",
    "            outf.write('<hr>')\n",
    "                \n",
    "        answ.append(answer.view(-1))\n",
    "        accs.append(acc.view(-1))\n",
    "        idxs.append(idx.view(-1).clone())\n",
    "        num_iters += 1\n",
    "        batch_id += 1\n",
    "        if num_iters == 1:\n",
    "            break\n",
    "            \n",
    "outf.write('</table></div></body></html>')\n",
    "outf.close()\n",
    "\n",
    "print(np.mean(avg_count))\n",
    "answ = list(torch.cat(answ, dim=0))\n",
    "accs = list(torch.cat(accs, dim=0))\n",
    "idxs = list(torch.cat(idxs, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_json['answer']['wood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tq = tqdm(LOADER, desc='{} E{:03d}'.format(PREFIX, 0), ncols=0)\n",
    "net.eval()\n",
    "answ = []\n",
    "idxs = []\n",
    "accs = []\n",
    "num_iters = 0\n",
    "batch_id = 0\n",
    "outf = open('/scratch/pramodkm/vqa/tsv/baseline_answers.html','w')\n",
    "html_str = '<head><link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css\" integrity=\"sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm\" crossorigin=\"anonymous\"></head>'\n",
    "html_str += '<body><div class=\"container\"> '\n",
    "outf.write(html_str)\n",
    "\n",
    "question = 'how many are not'\n",
    "question_tokens = torch.LongTensor([vocab_json['question'][w] for w in question.strip().split()] + [0]*(23-len(question.strip().split())))\n",
    "question_tokens = question_tokens.unsqueeze(0).repeat(config.batch_size,1)\n",
    "new_q_len = torch.LongTensor([len(question.strip().split())])\n",
    "new_q_len = new_q_len.repeat(config.batch_size)\n",
    "\n",
    "batch_percentages = np.zeros(3000)\n",
    "for v, q, a, idx, q_len in tq:\n",
    "        \n",
    "        var_params = {\n",
    "            'volatile': False,\n",
    "            'requires_grad': False,        \n",
    "        }\n",
    "                \n",
    "        v = Variable(v.cuda(async=True), **var_params)\n",
    "        q = Variable(q.cuda(async=True), **var_params)\n",
    "        question_tokens = Variable(question_tokens.cuda(async=True), **var_params)\n",
    "        a = Variable(a.cuda(async=True), **var_params)\n",
    "        q_len = Variable(q_len.cuda(async=True), **var_params)\n",
    "        new_q_len = Variable(new_q_len.cuda(async=True), **var_params)\n",
    "        \n",
    "        \n",
    "        # for baseline answers\n",
    "        baseline_q = q * 0   \n",
    "            \n",
    "        baseline_q_len = q_len/q_len\n",
    "        \n",
    "        baseline_q_emb = embedding(baseline_q)\n",
    "                \n",
    "        baseline_out = net(v, baseline_q_emb, baseline_q_len)    \n",
    "        \n",
    "        baseline_softmax = torch.nn.functional.softmax(baseline_out)\n",
    "\n",
    "        \n",
    "        test_k = 300          \n",
    "        test_q = question_tokens\n",
    "\n",
    "\n",
    "        batch_baseline_answers = []\n",
    "        for batch_i in range(config.batch_size):\n",
    "            baseline_probs, baseline_idxs = baseline_softmax[batch_i, :].sort(descending=True)\n",
    "            baseline_answers = [reverse_vocab_answer[int(ix)] for ix in baseline_idxs]\n",
    "            \n",
    "            counter = 4\n",
    "            for ba in baseline_answers[2:]:\n",
    "                if counter == 7:\n",
    "                    break\n",
    "                if ba not in vocab_json['question']:\n",
    "                    continue\n",
    "                test_q[batch_i, counter] = vocab_json['question'][ba]\n",
    "                counter += 1\n",
    "            test_out = net(v, embedding(test_q), new_q_len)\n",
    "            _, answer = test_out.data.cpu().max(dim=1)\n",
    "\n",
    "        for batch_i in range(config.batch_size):\n",
    "            baseline_probs, baseline_idxs = baseline_softmax[batch_i, :].sort(descending=True)\n",
    "            baseline_answers = [reverse_vocab_answer[int(ix)] for ix in baseline_idxs]\n",
    "            \n",
    "            baseline_probs = [float(prob) for prob in baseline_probs]\n",
    "            print_k = 100\n",
    "            outf.write(visualize_baseline_answers(baseline_answers[:print_k], baseline_probs[:print_k]))\n",
    "            outf.write('... ' + visualize_baseline_answers(baseline_answers[-10:], baseline_probs[-10:]))\n",
    "            image_id = str(val_loader.dataset.coco_ids[int(idx[batch_i])])\n",
    "            outf.write('<br>Question: ' + ' '.join([reverse_vocab_question[int(w)] for w in test_q[batch_i, :] if int(w)!=0]))\n",
    "            outf.write('<br>Pred. ans.: ' + reverse_vocab_answer[answer[batch_i]])\n",
    "            outf.write('<br><img src=\"val2014/COCO_val2014_' + '0'*(12 - len(str(image_id))) + str(image_id) + '.jpg\" width=\"256\" height=\"256\"></img><br><br>')\n",
    "            outf.write('<hr>')\n",
    "                      \n",
    "        \n",
    "\n",
    "        answ.append(answer.view(-1))\n",
    "        accs.append(acc.view(-1))\n",
    "        idxs.append(idx.view(-1).clone())\n",
    "        num_iters += 1\n",
    "        batch_id += 1\n",
    "        if num_iters == 1:\n",
    "            break\n",
    "            \n",
    "outf.write('</div></body>')\n",
    "outf.close()\n",
    "answ = list(torch.cat(answ, dim=0))\n",
    "accs = list(torch.cat(accs, dim=0))\n",
    "idxs = list(torch.cat(idxs, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(batch_percentages[:300]/300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_percentages/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_json['question']['rooster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(vocab_json['question'].keys()) - set(vocab_json['answer'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
